import sys
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage

# Fun√ß√£o principal que encapsula a l√≥gica
def generate_titles(transcript):
    """
    Usa o Google Gemini para gerar t√≠tulos de podcast com base em uma transcri√ß√£o.
    """
    load_dotenv()

    # Inicializa o modelo Gemini-2.0-flash com temperatura 0.7
    # Ajuste a temperatura conforme necess√°rio para variar a criatividade
    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash", temperature=0.7)

    # O prompt permanece o mesmo
    prompt = f"""
    Voc√™ √© um especialista em marketing digital e SEO, especializado em conte√∫do de podcasts.
    Sua tarefa √© criar 3 sugest√µes de t√≠tulos para um epis√≥dio de podcast com base na transcri√ß√£o fornecida.

    Regras:
    - Os t√≠tulos devem ser curtos, impactantes e otimizados para buscas (SEO-friendly).
    - Devem despertar curiosidade.
    - Devem refletir o conte√∫do principal da transcri√ß√£o.

    Transcri√ß√£o do epis√≥dio:
    ---
    {transcript}
    ---

    Gere os 3 t√≠tulos, cada um em uma nova linha, sem numera√ß√£o ou marcadores.
    """

    # Invoca o modelo e retorna o conte√∫do da resposta
    message = HumanMessage(content=prompt)
    response = llm.invoke([message])
    return response.content

if __name__ == "__main__":
    # 1. L√™ a transcri√ß√£o da entrada padr√£o (stdin)
    #    Isso permite que o Node.js envie dados para este script.
    transcript_from_input = sys.stdin.read()

    # 2. Escreve logs na sa√≠da de erro padr√£o (stderr)
    #    Isso evita que mensagens de log se misturem com o resultado final.
    print("--- üêç Script Python Recebeu a Transcri√ß√£o üêç ---", file=sys.stderr)

    # 3. Chama a fun√ß√£o principal com os dados recebidos
    generated_titles = generate_titles(transcript_from_input)

    # 4. Imprime o resultado final na sa√≠da padr√£o (stdout)
    #    √â S√ì ISSO que o Node.js ir√° capturar como resultado.
    print(generated_titles)